{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo : SVM for MNIST Digit Recognition\n",
    "\n",
    "In this demo, you will learn to:\n",
    "* Load and display images\n",
    "* Formulate image classification problems\n",
    "* Explain the limitations of linear classifiers for image classification\n",
    "* Build a simple SVM image classifier \n",
    "* Save and load results using `pickle`.\n",
    "\n",
    "For data, we will use the classic [MNIST](https://en.wikipedia.org/wiki/MNIST_database) data set used to recognize hand-written digits.  The dataset was originally produced in the 1980s and is now widely-used in machine learning classes as a simple image classification problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "First, we load the standard packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the MNIST dataset is so widely-used, it comes in as a build-in dataset in many packages. In this lab, we will download the data from the Tensorflow package -- See here for [installations instructions](https://www.tensorflow.org/install).  You can get the data from other sources as well. \n",
    "\n",
    "In the Tensorflow dataset, the training and test data are represented as arrays:\n",
    "\n",
    "     Xtr.shape = 60000 x 28 x 28\n",
    "     Xts.shape = 10000 x 28 x 28\n",
    "     \n",
    "The test data consists of `60000` images of size `28 x 28` pixels; the test data consists of `10000` images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr shape: (60000, 28, 28)\n",
      "Xts shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(Xtr,ytr),(Xts,yts) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print('Xtr shape: %s' % str(Xtr.shape))\n",
    "print('Xts shape: %s' % str(Xts.shape))\n",
    "\n",
    "ntr = Xtr.shape[0]\n",
    "nts = Xts.shape[0]\n",
    "nrow = Xtr.shape[1]\n",
    "ncol = Xtr.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pixel value is from `[0,255]`.  For this lab, it will be convenient to recale the value to -1 to 1 and reshape it as a `ntr x npix` and `nts x npix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npix = nrow*ncol\n",
    "Xtr = 2*(Xtr/255 - 0.5)\n",
    "Xtr = Xtr.reshape((ntr,npix))\n",
    "\n",
    "Xts = 2*(Xts/255 - 0.5)\n",
    "Xts = Xts.reshape((nts,npix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABeCAYAAAAUjW5fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plt_digit(x):\n",
    "    nrow = 28\n",
    "    ncol = 28\n",
    "    xsq = x.reshape((nrow,ncol))\n",
    "    plt.imshow(xsq,  cmap='Greys_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "# Select random digits\n",
    "nplt = 4\n",
    "Iperm = np.random.permutation(ntr)\n",
    "\n",
    "# Plot the images using the subplot command\n",
    "for i in range(nplt):\n",
    "    ind = Iperm[i]\n",
    "    plt.subplot(1,nplt,i+1)\n",
    "    plt_digit(Xtr[ind,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an SVM classifier\n",
    "\n",
    "We now try an SVM classifier.  The parameters are given by \n",
    "\n",
    "https://martin-thoma.com/svm-with-sklearn/\n",
    "\n",
    "This website has a nice summary of the main equations for SVM as well.  That site trained on 40000 samples and tested on 20000.  But, to make this run faster, we will train on 10000 and test on 10000.  If you increase to 40000 training samples, you can get past 99% accuracy.\n",
    "\n",
    "First, we import the SVM package and construct the SVC with the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "svc = svm.SVC(probability=False,  kernel=\"linear\", C=2.8, gamma=.0073,verbose=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we get the training and test data.  The features are re-scaled to be between -1 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the training data.  Again, this will take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntr1 = 5000\n",
    "nts1 = 5000\n",
    "Iperm_ts = np.random.permutation(nts) \n",
    "Xtr1 = Xtr[Iperm[:ntr1],:]\n",
    "ytr1 = ytr[Iperm[:ntr1]]\n",
    "Xts1 = Xts[Iperm_ts[:nts1],:]\n",
    "yts1 = yts[Iperm_ts[:nts1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=2.8, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0073, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(Xtr,ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results in case you want them without re-running the above the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open( \"mnist_svc.p\", \"wb\" ) as fp:\n",
    "    pickle.dump( [svc, Xtr1,ytr1], fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can skip this step if you run the classifier directly\n",
    "import pickle\n",
    "with open( \"mnist_svc.p\", \"rb\" ) as fp:\n",
    "    svc, Xtr1,ytr1 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy on the test data.  The prediction can take several minutes too -- SVMs are *very* slow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat_ts = svc.predict(Xts1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since even the prediction (sometimes called inference) is slow with SVMs, we will save the results in `pickle` file. Instead of running the prediction again, you can recapture the data with the following comamnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"mnist_svc_test.p\", \"wb\") as fp:\n",
    "    pickle.dump([Xts1,yts1,yhat_ts], fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"mnist_svc_test.p\", \"rb\") as fp:\n",
    "    Xts1,yts1,yhat_ts = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuaracy = 0.934000\n"
     ]
    }
   ],
   "source": [
    "acc = np.mean(yhat_ts == yts1)\n",
    "print('Accuaracy = {0:f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get an accuracy of around 93%.  Again, had you trained on all 50,000 samples, it would have been much better -- close to 98.5%.  But, even this result is much better than logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the Support Vectors\n",
    "\n",
    "Let's take a look at the support vectors.  We see there about over 2500 support vectors.  So, about quarter the training samples were used as SVs.  This is partly why the prediction was so slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10124, 784)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = svc.support_vectors_\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot some support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAACOCAYAAAAy0AzYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nplt = 4\n",
    "nsv = S.shape[0]\n",
    "Iperms = np.random.permutation(nsv)\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(nplt):        \n",
    "    plt.subplot(1,nplt,i+1)        \n",
    "    ind = Iperms[i]\n",
    "    plt_digit(S[ind,:])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the support vectors look like digits we want to recognize. They are like the 'match filters'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we specified the parameters for the SVC. In the lab, you will be asked to find the optimal parameters through cross validation."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
